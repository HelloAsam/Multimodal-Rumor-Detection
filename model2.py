# ============================================
# æ¨¡å— 1. åŠ è½½ä¾èµ–
# ============================================
import os
import pandas as pd
from PIL import Image
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import AutoTokenizer, AutoModel, ViTImageProcessor, ViTModel

# ============================================
# æ¨¡å— 2. è®¾ç½®å‚æ•° & è·¯å¾„
# ============================================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MAX_LEN = 128
BATCH_SIZE = 8

DATA_DIR = "./data"
IMAGE_ROOT = "./images"

# æ¨¡å‹è·¯å¾„ï¼ˆä½ ä¹‹å‰å·²ä¸‹è½½ï¼‰
BERT_PATH = "./pretrained/chinese-bert-wwm-ext"
VIT_PATH = "./pretrained/vit-base-patch16-224"

# ============================================
# æ¨¡å— 3. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
# ============================================
bert_tokenizer = AutoTokenizer.from_pretrained(BERT_PATH)
bert_model = AutoModel.from_pretrained(BERT_PATH).to(DEVICE)

vit_processor = ViTImageProcessor.from_pretrained(VIT_PATH)
vit_model = ViTModel.from_pretrained(VIT_PATH).to(DEVICE)

# ============================================
# æ¨¡å— 4. ç”Ÿæˆç»Ÿä¸€ DataFrame
# ============================================
def load_meta(meta_path, social_path, split_name):
    """
    ä» meta.xlsx å’Œ social_feature.xlsx æ„é€ ç»Ÿä¸€ DataFrame
    """
    # è¯»å– metaï¼ˆå« weibo_id, text, image_files, labelï¼‰
    df = pd.read_excel(meta_path)

    # è¯»å–ç¤¾äº¤ç‰¹å¾
    social_df = pd.read_excel(social_path)

    # weibo_id è½¬å­—ç¬¦ä¸²ï¼Œé¿å…ç§‘å­¦è®¡æ•°æ³•
    df["weibo_id"] = df["weibo_id"].astype(str)
    social_df["weibo_id"] = social_df["weibo_id"].astype(str)

    # åˆå¹¶ (inner join)
    df = df.merge(social_df, on="weibo_id", how="inner")

    # æå–ç¤¾äº¤ç‰¹å¾åˆ—
    feature_cols = [c for c in df.columns if c not in ["weibo_id", "text", "image_files", "image_count", "label"]]
    df["social_features"] = df[feature_cols].values.tolist()

    # ä¿ç•™å…³é”®åˆ—
    df = df[["weibo_id", "text", "image_files", "social_features", "label"]]

    print(f"{split_name} æ ·æœ¬æ•°: {len(df)}")
    return df

social_path = os.path.join(DATA_DIR, "social_feature.xlsx")
train_df = load_meta(os.path.join(DATA_DIR, "train_meta.xlsx"), social_path, "è®­ç»ƒé›†")
val_df   = load_meta(os.path.join(DATA_DIR, "val_meta.xlsx"), social_path, "éªŒè¯é›†")
test_df  = load_meta(os.path.join(DATA_DIR, "test_meta.xlsx"), social_path, "æµ‹è¯•é›†")

# ============================================
# æ¨¡å— 5. å®šä¹‰ Dataset
# ============================================
class WeiboDataset(Dataset):
    def __init__(self, df, text_tokenizer, image_processor, image_root=IMAGE_ROOT, max_len=MAX_LEN):
        self.df = df.reset_index(drop=True)
        self.text_tokenizer = text_tokenizer
        self.image_processor = image_processor
        self.image_root = image_root
        self.max_len = max_len

        # è°ƒè¯•ï¼šæ‰“å°ç©ºæ–‡æœ¬æ•°é‡
        empty_count = self.df["text"].isna().sum()
        print(f"ğŸ“Š å½“å‰æ•°æ®é›†ä¸­ç©ºæ–‡æœ¬æ•°é‡: {empty_count}")

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]

        # ========= æ–‡æœ¬å¤„ç† =========
        text = row["text"]
        if not isinstance(text, str):
            text = ""   # é¿å… NaN æˆ–æ•°å­—æŠ¥é”™

        text_inputs = self.text_tokenizer(
            text,
            padding="max_length",
            truncation=True,
            max_length=self.max_len,
            return_tensors="pt"
        )

        # ========= å›¾åƒå¤„ç†ï¼ˆå¤šå›¾ â†’ mean poolingï¼‰=========
        img_files = str(row["image_files"]).split(",")
        img_list = []
        for fname in img_files:
            path = os.path.join(self.image_root, fname.strip())
            if not os.path.exists(path):
                continue
            try:
                image = Image.open(path).convert("RGB")
                inputs = self.image_processor(images=image, return_tensors="pt")
                img_list.append(inputs["pixel_values"].squeeze(0))
            except Exception as e:
                print(f"âŒ å›¾åƒè¯»å–å¤±è´¥: {path}, é”™è¯¯: {e}")
                continue

        if len(img_list) == 0:
            img_tensor = torch.zeros(3, 224, 224)  # å ä½
        else:
            img_tensor = torch.stack(img_list).mean(dim=0)

        # ========= ç¤¾äº¤ç‰¹å¾ =========
        social_feat = torch.tensor(row["social_features"], dtype=torch.float)

        label = int(row["label"])

        return {
            "input_ids": text_inputs["input_ids"].squeeze(0),
            "attention_mask": text_inputs["attention_mask"].squeeze(0),
            "pixel_values": img_tensor,
            "social_features": social_feat,
            "label": label
        }


# ============================================
# æ¨¡å— 6. å®šä¹‰å¤šæ¨¡æ€æ¨¡å‹ï¼ˆæ”¯æŒéƒ¨åˆ†è§£å†»ï¼‰
# ============================================
class MultiModalModel(nn.Module):
    def __init__(self, bert, vit, social_dim=16, hidden_dim=256, num_classes=2,
                 freeze_backbone=True, unfreeze_last_n=0):
        super().__init__()
        self.bert = bert
        self.vit = vit

        # ===== å…ˆå†»ç»“æ‰€æœ‰å‚æ•° =====
        if freeze_backbone:
            for param in self.bert.parameters():
                param.requires_grad = False
            for param in self.vit.parameters():
                param.requires_grad = False

        # ===== å¦‚æœæŒ‡å®š unfreeze_last_n > 0ï¼Œå°±è§£å†» BERT / ViT çš„åå‡ å±‚ =====
        if unfreeze_last_n > 0:
            # BERT: encoder.layer[-n:]
            for layer in self.bert.encoder.layer[-unfreeze_last_n:]:
                for param in layer.parameters():
                    param.requires_grad = True
            # BERT pooler ä¹Ÿè§£å†»ï¼ˆå¯é€‰ï¼‰
            for param in self.bert.pooler.parameters():
                param.requires_grad = True

            # ViT: encoder.layer[-n:]
            for layer in self.vit.encoder.layer[-unfreeze_last_n:]:
                for param in layer.parameters():
                    param.requires_grad = True
            # ViT pooler ä¹Ÿè§£å†»ï¼ˆå¯é€‰ï¼‰
            for param in self.vit.pooler.parameters():
                param.requires_grad = True

        # ===== æŠ•å½±å±‚ =====
        self.text_proj = nn.Linear(768, hidden_dim)
        self.img_proj = nn.Linear(768, hidden_dim)
        self.social_proj = nn.Linear(social_dim, hidden_dim)

        # ===== ä¸‰å±‚ MLP åˆ†ç±»å¤´ =====
        self.classifier = nn.Sequential(
            nn.Linear(hidden_dim * 3, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim // 2, num_classes)
        )

        # ===== æ‰“å°å‚æ•°ä¿¡æ¯ =====
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)

        def format_params(n):
            if n >= 1e6:
                return f"{n/1e6:.2f}M"
            elif n >= 1e3:
                return f"{n/1e3:.2f}K"
            return str(n)

        print("ğŸ“Š æ¨¡å‹å‚æ•°é‡ç»Ÿè®¡:")
        print(f"  æ€»å‚æ•°: {total_params} ({format_params(total_params)})")
        print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params} ({format_params(trainable_params)})")
        print(f"  å†»ç»“å‚æ•°: {total_params - trainable_params} ({format_params(total_params - trainable_params)})")

    def forward(self, input_ids, attention_mask, pixel_values, social_features):
        # æ–‡æœ¬ç‰¹å¾
        text_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        text_feat = self.text_proj(text_out.pooler_output)  # [B, hidden_dim]

        # å›¾åƒç‰¹å¾
        img_out = self.vit(pixel_values=pixel_values)
        img_feat = self.img_proj(img_out.pooler_output)  # [B, hidden_dim]

        # ç¤¾äº¤ç‰¹å¾
        social_feat = self.social_proj(social_features)

        # èåˆ
        fused = torch.cat([text_feat, img_feat, social_feat], dim=1)

        return self.classifier(fused)



# ============================================
# æ¨¡å— 7. æ•°æ®åŠ è½½å™¨
# ============================================
train_dataset = WeiboDataset(train_df, bert_tokenizer, vit_processor)
val_dataset   = WeiboDataset(val_df, bert_tokenizer, vit_processor)
test_dataset  = WeiboDataset(test_df, bert_tokenizer, vit_processor)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE)
test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE)

# ============================================
# æ¨¡å— 8. æ¨¡å‹æµ‹è¯•å‰å‘
# ============================================
# è§£å†» BERT å’Œ ViT çš„åä¸¤å±‚
model = MultiModalModel(
    bert_model,
    vit_model,
    freeze_backbone=True,   # å…ˆå†»ç»“
    unfreeze_last_n=2       # å†è§£å†»åä¸¤å±‚
).to(DEVICE)

# å–ä¸€ä¸ª batch æµ‹è¯• forward
batch = next(iter(train_loader))
out = model(
    batch["input_ids"].to(DEVICE),
    batch["attention_mask"].to(DEVICE),
    batch["pixel_values"].to(DEVICE),
    batch["social_features"].to(DEVICE)
)

print("è¾“å‡ºç»´åº¦:", out.shape)  # [B, 2]



# ============================================
# æ¨¡å— 9. è®­ç»ƒ & éªŒè¯å‡½æ•° (å¢å¼ºç‰ˆ: è¾“å‡ºåˆ†ç±»æŒ‡æ ‡)
# ============================================
from torch.optim import AdamW
from sklearn.metrics import accuracy_score, f1_score, classification_report
import numpy as np

def get_metrics(y_true, y_pred):
    report = classification_report(y_true, y_pred, target_names=["nonrumor(0)", "rumor(1)"], digits=4, output_dict=True)
    return {
        "acc": accuracy_score(y_true, y_pred),
        "macro_f1": f1_score(y_true, y_pred, average="macro"),
        "precision_0": report["nonrumor(0)"]["precision"],
        "recall_0": report["nonrumor(0)"]["recall"],
        "f1_0": report["nonrumor(0)"]["f1-score"],
        "precision_1": report["rumor(1)"]["precision"],
        "recall_1": report["rumor(1)"]["recall"],
        "f1_1": report["rumor(1)"]["f1-score"],
    }

def train_one_epoch(model, dataloader, optimizer, criterion):
    model.train()
    total_loss, preds_all, labels_all = 0, [], []

    for batch in dataloader:
        optimizer.zero_grad()

        outputs = model(
            batch["input_ids"].to(DEVICE),
            batch["attention_mask"].to(DEVICE),
            batch["pixel_values"].to(DEVICE),
            batch["social_features"].to(DEVICE)
        )

        labels = batch["label"].to(DEVICE)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        preds_all.extend(outputs.argmax(1).cpu().tolist())
        labels_all.extend(labels.cpu().tolist())

    metrics = get_metrics(labels_all, preds_all)
    metrics["loss"] = total_loss / len(dataloader)
    return metrics

def evaluate(model, dataloader, criterion):
    model.eval()
    total_loss, preds_all, labels_all = 0, [], []

    with torch.no_grad():
        for batch in dataloader:
            outputs = model(
                batch["input_ids"].to(DEVICE),
                batch["attention_mask"].to(DEVICE),
                batch["pixel_values"].to(DEVICE),
                batch["social_features"].to(DEVICE)
            )
            labels = batch["label"].to(DEVICE)
            loss = criterion(outputs, labels)

            total_loss += loss.item()
            preds_all.extend(outputs.argmax(1).cpu().tolist())
            labels_all.extend(labels.cpu().tolist())

    metrics = get_metrics(labels_all, preds_all)
    metrics["loss"] = total_loss / len(dataloader)
    return metrics


# ============================================
# æ¨¡å— 10. è®­ç»ƒä¸»å¾ªç¯ (æ—©åœ + æ—¥å¿—å¢å¼ºç‰ˆ)
# ============================================
import csv

EPOCHS = 30
LR = 2e-5
PATIENCE = 5

criterion = nn.CrossEntropyLoss()
optimizer = AdamW(model.parameters(), lr=LR)

best_val_f1 = 0.0
patience_counter = 0

# ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
os.makedirs("model", exist_ok=True)
os.makedirs("tmp", exist_ok=True)

# æ—¥å¿—æ–‡ä»¶è·¯å¾„
log_path = os.path.join("tmp", "training_log.csv")

# å†™å…¥è¡¨å¤´
with open(log_path, mode="w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    headers = [
        "epoch",
        # train
        "train_loss", "train_acc", "train_macro_f1",
        "train_precision_0", "train_recall_0", "train_f1_0",
        "train_precision_1", "train_recall_1", "train_f1_1",
        # val
        "val_loss", "val_acc", "val_macro_f1",
        "val_precision_0", "val_recall_0", "val_f1_0",
        "val_precision_1", "val_recall_1", "val_f1_1"
    ]
    writer.writerow(headers)

for epoch in range(EPOCHS):
    print(f"\nğŸ”¹ Epoch {epoch+1}/{EPOCHS}")

    train_metrics = train_one_epoch(model, train_loader, optimizer, criterion)
    val_metrics = evaluate(model, val_loader, criterion)

    print(f"è®­ç»ƒé›†: Loss={train_metrics['loss']:.4f}, Acc={train_metrics['acc']:.4f}, F1={train_metrics['macro_f1']:.4f}")
    print(f"éªŒè¯é›†: Loss={val_metrics['loss']:.4f}, Acc={val_metrics['acc']:.4f}, F1={val_metrics['macro_f1']:.4f}")

    # ä¿å­˜æ—¥å¿—
    with open(log_path, mode="a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        row = [epoch+1] + [
            train_metrics["loss"], train_metrics["acc"], train_metrics["macro_f1"],
            train_metrics["precision_0"], train_metrics["recall_0"], train_metrics["f1_0"],
            train_metrics["precision_1"], train_metrics["recall_1"], train_metrics["f1_1"],
            val_metrics["loss"], val_metrics["acc"], val_metrics["macro_f1"],
            val_metrics["precision_0"], val_metrics["recall_0"], val_metrics["f1_0"],
            val_metrics["precision_1"], val_metrics["recall_1"], val_metrics["f1_1"]
        ]
        writer.writerow(row)

    # æ—©åœæœºåˆ¶
    if val_metrics["macro_f1"] > best_val_f1:
        best_val_f1 = val_metrics["macro_f1"]
        torch.save(model.state_dict(), os.path.join("model", "best_multimodal_model.pth"))
        print("âœ… æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ° ./model/best_multimodal_model.pth")
        patience_counter = 0
    else:
        patience_counter += 1
        print(f"âš ï¸ éªŒè¯ F1 æ²¡æå‡, patience={patience_counter}/{PATIENCE}")

        if patience_counter >= PATIENCE:
            print("â¹ï¸ è§¦å‘æ—©åœæœºåˆ¶ï¼Œè®­ç»ƒæå‰ç»“æŸ")
            break

# ============================================
# æ¨¡å— 11. æµ‹è¯•é›†è¯„ä¼° (ç»“æœå†™å…¥ training_log.csv + ä¿å­˜æ··æ·†çŸ©é˜µ)
# ============================================
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

print("\n=== åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° ===")
model.load_state_dict(torch.load(os.path.join("model", "best_multimodal_model.pth")))
test_metrics = evaluate(model, test_loader, criterion)

print(f"\nğŸ“Š æµ‹è¯•é›†æ•´ä½“è¡¨ç°: Loss={test_metrics['loss']:.4f}, "
      f"Acc={test_metrics['acc']:.4f}, Macro-F1={test_metrics['macro_f1']:.4f}")

# æ”¶é›†é¢„æµ‹ä¸æ ‡ç­¾
model.eval()
all_preds, all_labels = [], []
with torch.no_grad():
    for batch in test_loader:
        outputs = model(
            batch["input_ids"].to(DEVICE),
            batch["attention_mask"].to(DEVICE),
            batch["pixel_values"].to(DEVICE),
            batch["social_features"].to(DEVICE)
        )
        preds = outputs.argmax(1).cpu().numpy()
        labels = batch["label"].cpu().numpy()
        all_preds.extend(preds)
        all_labels.extend(labels)

# åˆ†ç±»æŠ¥å‘Š
report = classification_report(
    all_labels, all_preds,
    target_names=["nonrumor(0)", "rumor(1)"],
    digits=4
)
print("\nğŸ“‘ åˆ†ç±»æŠ¥å‘Š:")
print(report)

# æ··æ·†çŸ©é˜µ
cm = confusion_matrix(all_labels, all_preds)
print("\nğŸ§© æ··æ·†çŸ©é˜µ:")
print(cm)

# ä¿å­˜æ··æ·†çŸ©é˜µ
os.makedirs("tmp", exist_ok=True)
np.save(os.path.join("tmp", "confusion_matrix.npy"), cm)
print("âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ° tmp/confusion_matrix.npy")

# === æŠŠæµ‹è¯•é›†ç»“æœå†™å…¥ training_log.csv ===
with open(log_path, mode="a", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    row = ["TEST"] + [
        test_metrics["loss"], test_metrics["acc"], test_metrics["macro_f1"],
        test_metrics["precision_0"], test_metrics["recall_0"], test_metrics["f1_0"],
        test_metrics["precision_1"], test_metrics["recall_1"], test_metrics["f1_1"],
        "-", "-", "-", "-", "-", "-", "-", "-", "-"
    ]
    writer.writerow(row)

print(f"\nâœ… æµ‹è¯•ç»“æœå·²è¿½åŠ åˆ° {log_path}")
